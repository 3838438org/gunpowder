import logging
import os

from gunpowder.ext import tensorflow as tf
from gunpowder.nodes.generic_train import GenericTrain
from gunpowder.volume import VolumeType, Volume

logger = logging.getLogger(__name__)

class Train(GenericTrain):
    '''Tensorflow implementation of :class:`gunpowder.nodes.Train`.

    Args:

        meta_graph_filename: Filename of a tensorflow meta-graph storing the
            tensorflow graph containing an optimizer. A meta-graph file can be
            created by running::

                # create tensorflow graph
                ...

                # store it
                tf.train.export_meta_graph(filename=meta_graph_filename)

        optimizer: The name of the tensorflow operator performing a training
            iteration.

        loss: The name of the tensorflow tensor containing the loss.

        inputs (dict): Dictionary from :class:``VolumeType`` or batch attribute
            name as string to the names of input tensors in the network.

        outputs (dict): Dictionary from :class:``VolumeType`` to the names of
            output tensors of the network. New volumes will be generated by
            this node for each entry (if requested downstream).

        gradients (dict): Dictionary from :class:``VolumeType`` to the names of
            output tensors of the network. New volumes containing the gradient
            of an output with respect to the loss will be generated by this
            node for each entry (if requested downstream).

        volume_specs (dict, optional): An optional dictionary of
            :class:`VolumeType` to :class:`VolumeSpec` to set the volume specs
            generated volumes (``outputs`` and ``gradients``). This is useful
            to set the ``voxel_size``, for example, if they differ from the
            voxel size of the input volumes. Only fields that are not ``None``
            in the given :class:`VolumeSpec` will be used.
    '''

    def __init__(
            self,
            meta_graph_filename,
            optimizer,
            loss,
            inputs,
            outputs,
            gradients,
            volume_specs=None):

        super(Train, self).__init__(
            inputs,
            outputs,
            gradients,
            volume_specs,
            spawn_subprocess=False)
        self.meta_graph_filename = meta_graph_filename
        self.optimizer = optimizer
        self.loss = loss
        self.session = None

    def initialize(self):

        logger.info("Initializing tf session...")

        graph = tf.Graph()
        self.session = tf.Session(graph=graph)

        with graph.as_default():

            logger.info("Reading meta-graph...")

            saver = tf.train.import_meta_graph(
                self.meta_graph_filename + '.meta',
                clear_devices=True)

            print [x.name for x in graph.get_operations() ]

            checkpoint_dir = os.path.dirname(self.meta_graph_filename)
            checkpoint = tf.train.latest_checkpoint(checkpoint_dir)

            if checkpoint is not None:
                logger.info("Restoring weights from %s", checkpoint)
                saver.restore(self.session, checkpoint)
            else:
                self.session.run(tf.global_variables_initializer())

        # replace names of operations/tensors with actual operations/tensors
        self.optimizer = graph.get_operation_by_name(self.optimizer)
        self.loss = graph.get_tensor_by_name(self.loss)

    def train_step(self, batch, request):

        to_compute = {'optimizer': self.optimizer, 'loss': self.loss}
        to_compute.update(self.outputs)

        feed_dict = {}
        for network_input, input_name in self.inputs.items():
            if isinstance(network_input, VolumeType):
                feed_dict[input_name] = batch.volumes[network_input].data
            elif isinstance(network_input, str):
                feed_dict[input_name] = getattr(batch, network_input)
            else:
                raise Exception(
                    "Unknown network input type {}, can't be given to "
                    "network".format(network_input))

        outputs = self.session.run(to_compute, feed_dict=feed_dict)

        for volume_type, _ in self.outputs.items():
            if volume_type in request:
                spec = self.spec[volume_type].copy()
                spec.roi = request[volume_type].roi
                batch.volumes[volume_type] = Volume(
                    outputs[volume_type],
                    spec)

        # TODO: how to get gradients from tf?
        # if len(self.gradients) > 0:

            # diffs = self.net_io.get_output_diffs()

            # for volume_type, output_name in self.gradients.items():
                # batch.volumes[volume_type] = Volume(
                        # data=diffs[output_name][0], # strip #batch dimension
                        # roi=Roi((0,0,0),diffs[output_name][0].shape[-3:])) # dummy roi, will be corrected in process()

        batch.loss = outputs['loss']
        # TODO: get iteration
        batch.iteration = 0
